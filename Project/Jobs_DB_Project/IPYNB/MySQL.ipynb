{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import pandas as pd\n",
    "import sys, getopt, pprint\n",
    "import twitter\n",
    "import tweepy\n",
    "import time\n",
    "import collections \n",
    "import datetime \n",
    "import re\n",
    "import pymongo\n",
    "from bson import json_util, ObjectId\n",
    "import numpy as np\n",
    "import requests\n",
    "import configparser\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import random\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import MySQLdb\n",
    "import sqlalchemy\n",
    "import pprint\n",
    "import os\n",
    "import bson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MIT License\n",
    "\n",
    "#Copyright <YEAR> <COPYRIGHT HOLDER>\n",
    "\n",
    "#Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "#The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "#THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Application authoration information\n",
    "CONSUMER_KEY = 'kPDlBul6nS3moLfGmLvwM3pLm'\n",
    "CONSUMER_SECRET = 'EQ8nv28WyALnhZ8jehwGlLepMB7eBzKDOZOggnIsqukWcIFX1A'\n",
    "OAUTH_TOKEN = '3910298715-SQR4mBRJe1G59wybNQbo1NvCFneJRuIqd3D18CB'\n",
    "OAUTH_TOKEN_SECRET = '86pVFTMoquM1h753aPvNV6GHcEuu5FUD6URn5pZA90xiJ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building connction with tweepy\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True, retry_count=3, retry_delay=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create empty list for data extraction\n",
    "t = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data extraction using tweepy api and store data in empty list. \n",
    "for tweet in tweepy.Cursor(api.search, q=('monster hunter world'), since='2018-04-19', until='2018-04-20').items(100):\n",
    "    #tweet_id = tweet.id\n",
    "    t += [{ 'Tweet_id': tweet.id,\n",
    "            'Game_id': '488',\n",
    "            'Screen_name':tweet.author.screen_name.encode('utf8'),\n",
    "            'Created_at':tweet.created_at,\n",
    "            'Tweet_text':tweet.text.encode('utf8'),\n",
    "            'Hashtags':re.findall(r\"#(\\w+)\",tweet.text),\n",
    "            'Retweets':tweet.retweet_count,\n",
    "            'Favorites':tweet.favorite_count,\n",
    "            'Location':tweet.user.location.encode('utf8')}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Convert list into pandas dataframe. \n",
    "df1 = pd.DataFrame(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Self define functions for data cleaning. \n",
    "def change_column_order(df, col_name, index):\n",
    "    cols = df.columns.tolist()\n",
    "    cols.remove(col_name)\n",
    "    cols.insert(index, col_name)\n",
    "    return df[cols]\n",
    "\n",
    "def split_df(dataframe, col_name, sep):\n",
    "    orig_col_index = dataframe.columns.tolist().index(col_name)\n",
    "    orig_index_name = dataframe.index.name\n",
    "    orig_columns = dataframe.columns\n",
    "    dataframe = dataframe.reset_index()  # we need a natural 0-based index for proper merge\n",
    "    index_col_name = (set(dataframe.columns) - set(orig_columns)).pop()\n",
    "    df_split = pd.DataFrame(\n",
    "        pd.DataFrame(dataframe[col_name].str.split(sep).tolist())\n",
    "        .stack().reset_index(level=1, drop=1), columns=[col_name])\n",
    "    df = dataframe.drop(col_name, axis=1)\n",
    "    df = pd.merge(df, df_split, left_index=True, right_index=True, how='inner')\n",
    "    df = df.set_index(index_col_name)\n",
    "    df.index.name = orig_index_name\n",
    "    # merge adds the column to the last place, so we need to move it back\n",
    "    return change_column_order(df, col_name, orig_col_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning procedure.\n",
    "df1['Hashtags'] = df1['Hashtags'].astype('str')\n",
    "df1['Created_at'] = df1['Created_at'].astype('str')\n",
    "df1['Screen_name'] = df1['Screen_name'].astype('str')\n",
    "df1['Tweet_text'] = df1['Tweet_text'].astype('str')\n",
    "df1['Tweet_id']= df1['Tweet_id'].astype('str')\n",
    "df1['Location']= df1['Location'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning procedure cont. \n",
    "df1['Hashtags'] = df1['Hashtags'].str.replace('[','')\n",
    "df1['Hashtags'] = df1['Hashtags'].str.replace(']','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning procedure cont. \n",
    "df1 = split_df(df1, 'Hashtags', ', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning procedure cont. \n",
    "df1['Screen_name']=df1['Screen_name'].str[2:-1]\n",
    "df1['Tweet_text'] = df1['Tweet_text'].str[2:-1]\n",
    "df1['Location']=df1['Location'].str[2:-1]\n",
    "df1['Tweet_id1']=df1['Tweet_id'].str[:9]\n",
    "df1['Tweet_id2']=df1['Tweet_id'].str[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning procedure cont. \n",
    "df1 = df1.drop(['Tweet_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning procedure cont. \n",
    "df1['Hashtags']=df1['Hashtags'].str[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning procedure cont. \n",
    "df1['Tweet_date']=df1['Created_at'].str[:10]\n",
    "df1['Tweet_time']=df1['Created_at'].str[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning procedure cont. \n",
    "df1 = df1.drop(['Created_at'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the values for database connection\n",
    "dsn_database = \"project\"   # e.g. \"MySQLdbtest\"\n",
    "dsn_hostname = \"127.0.0.1\"       # e.g.: \"mydbinstance.xyz.us-east-1.rds.amazonaws.com\"\n",
    "dsn_port = 3306                        # e.g. 3306 \n",
    "dsn_uid = \"root\"             # e.g. \"user1\"\n",
    "dsn_pwd = \"12345\"            # e.g. \"Password123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sqlalchemy package creates connection with mysql database to import dataframe into MySQL.\n",
    "database_connection = sqlalchemy.create_engine('mysql+mysqlconnector://{0}:{1}@{2}/{3}'.\n",
    "                                               format(dsn_uid, dsn_pwd, \n",
    "                                                      dsn_hostname, dsn_database))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing file into MySQL. \n",
    "df1.to_sql(con=database_connection, name='tweets', if_exists='append',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create connection with MySQL using MySQLdb to perform selection. \n",
    "conn = MySQLdb.connect(host=dsn_hostname, port=dsn_port, user=dsn_uid, passwd=dsn_pwd, db=dsn_database)\n",
    "cursor=conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('02',),\n",
      " ('1',),\n",
      " ('14',),\n",
      " ('2',),\n",
      " ('3',),\n",
      " ('5',),\n",
      " ('5060',),\n",
      " ('50K',),\n",
      " ('5739',),\n",
      " ('BonPlan',))\n"
     ]
    }
   ],
   "source": [
    "#1. What are people saying about me (somebody)?\n",
    "# Select all hashtags included in all tweets about this game. \n",
    "cursor.execute(\"\"\"select Hashtags from Tweets where Hashtags is not null GROUP BY Hashtags limit 10\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((20095, 986019774, 399434753),\n",
      " (7447, 986393866, 877087746),\n",
      " (1356, 986393207, 306051584),\n",
      " (1086, 985658666, 593472513),\n",
      " (912, 986393139, 370799104),\n",
      " (464, 986392164, 769976320),\n",
      " (459, 986755483, 590537216),\n",
      " (407, 986393803, 433979904),\n",
      " (311, 986746988, 682084353),\n",
      " (213, 986393685, 737787392))\n"
     ]
    }
   ],
   "source": [
    "#2. How viral are my posts?\n",
    "# Order tweets by retweet numbers. \n",
    "cursor.execute(\"\"\"select Retweets, Tweet_id1, Tweet_id2 from Tweets where Retweets != 0 group by Tweet_text order by Retweets DESC limit 10\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((44, 2, 987103597, 262442496),\n",
      " (16, 3, 986749897, 717231621),\n",
      " (9, 8, 986020388, 462383107),\n",
      " (8, 4, 985668186, 518335488),\n",
      " (8, 2, 985650733, 797257216),\n",
      " (7, 3, 985664925, 761613824),\n",
      " (6, 1, 985661712, 736116742),\n",
      " (5, 2, 985665132, 226334720),\n",
      " (5, 1, 986024159, 70343173),\n",
      " (5, 10, 986016914, 43420672))\n"
     ]
    }
   ],
   "source": [
    "#3. How much influence to my posts have?\n",
    "# Order tweets by favorite number \n",
    "cursor.execute(\"\"\"select Favorites, Retweets, Tweet_id1, Tweet_id2 from tweets where Retweets !=0 and Favorites !=0 group by Tweet_text order by Favorites DESC limit 10\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((985666520, 75218944),\n",
      " (985666264, 348659714),\n",
      " (985665957, 464039424),\n",
      " (985665458, 459291648),\n",
      " (985663785, 808662528),\n",
      " (985660602, 34122752),\n",
      " (985656642, 44805120),\n",
      " (985655896, 897478657),\n",
      " (985655059, 34845185),\n",
      " (985653975, 994241024))\n"
     ]
    }
   ],
   "source": [
    "#4. What posts are like mine?\n",
    "# Select tweets with same hashtag. \n",
    "cursor.execute(\"\"\"select tweet_id1,tweet_id2 from tweets where Hashtags='PS4live' limit 10\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('TM_SweetTooth',),\n",
      " ('raceryayo',),\n",
      " ('Hphsbillz',),\n",
      " ('JF_Chabot',),\n",
      " ('Tr11Royalty',),\n",
      " ('Papichulo_KD',),\n",
      " ('KennyJay305',),\n",
      " ('EP1C_K1LLSW1TCH',),\n",
      " ('mdawggaming',),\n",
      " ('FetterlyTravis',))\n"
     ]
    }
   ],
   "source": [
    "#5. What users post like me?\n",
    "#Select screen_name used the same hashtags in their tweets. \n",
    "cursor.execute(\"\"\"select distinct Screen_name from tweets where Hashtags = 'PS4live' limit 10\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('dealPS4', 5),\n",
      " ('MissMesho', 5),\n",
      " ('GermanTwitchRT', 4),\n",
      " ('StreamAcademyRT', 4),\n",
      " ('Death280', 4),\n",
      " ('ADSPLAY101', 4),\n",
      " ('pino_4521', 4),\n",
      " ('deals_vtipha', 3),\n",
      " ('MrJoeyOverdose', 3),\n",
      " ('AngeloOhhBaby', 3))\n"
     ]
    }
   ],
   "source": [
    "#6. Who should I be following?\n",
    "#Select users who post about this topic the most. \n",
    "cursor.execute(\"\"\"select Screen_name, count(*) from tweets group by Screen_name order by count(*) DESC limit 10;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('PS4live', 15), ('Twitch', 3), ('Streaming', 3))\n"
     ]
    }
   ],
   "source": [
    "#7. What topics are trending in my domain?\n",
    "# Select most used hashtags in a certain date to represent the trends. \n",
    "cursor.execute(\"\"\"select Hashtags,count(Hashtags)from tweets where Hashtags is not null and Tweet_date='2018-04-19' group by Hashtags order by count(Hashtags) DESC limit 3\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('MHWorld', 54), ('PS4live', 45), ('MonsterHunterWorld', 9))\n"
     ]
    }
   ],
   "source": [
    "#8. What keywords hashtags should I add to my post?\n",
    "# Select the most used hashtags. \n",
    "cursor.execute(\"\"\"select Hashtags,count(Hashtags) from tweets where Hashtags is not null group by Hashtags order by count(Hashtags) DESC limit 3;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('dealPS4', 5), ('MissMesho', 5), ('GermanTwitchRT', 4))\n"
     ]
    }
   ],
   "source": [
    "#9. Should I follow somebody back?\n",
    "#Select the top 3 users posting about this topic. \n",
    "cursor.execute(\"\"\"select Screen_name, count(*) from tweets group by Screen_name order by count(*) DESC limit 3;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('23:59:58', 5), ('23:40:25', 5), ('23:57:21', 4))\n"
     ]
    }
   ],
   "source": [
    "#10. What is the best time to post?\n",
    "#Select time point with most tweets occured. \n",
    "cursor.execute(\"\"\"select Tweet_time, count(Tweet_time) from tweets group by Tweet_time order by count(Tweet_time) DESC Limit 3;\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('#GamingIsInOurBlood',),\n",
      " ('40.868181,-73.963332',),\n",
      " ('A Computer Somewhere',),\n",
      " ('a hole',),\n",
      " ('AB, Canada',),\n",
      " ('Alabama, USA',),\n",
      " ('Algiers                       ',),\n",
      " ('Alternative Reality, USA',),\n",
      " ('Amiens, France',),\n",
      " ('Amsterdam, Nederland',))\n"
     ]
    }
   ],
   "source": [
    "#13. Whatâ€™s my reach?\n",
    "# From Japan to the location of all the tweets. \n",
    "cursor.execute(\"\"\"select distinct Location from tweets where Location is not null limit 10\"\"\")\n",
    "rows = cursor.fetchall()\n",
    "pprint.pprint(rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
